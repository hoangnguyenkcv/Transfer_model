{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Activation, Lambda, Permute, Reshape, Merge\n",
    "from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import  BatchNormalization\n",
    "from keras.layers.convolutional import *\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import theano\n",
    "import  matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "import itertools\n",
    "from numpy import*\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "import random as rn\n",
    "import os\n",
    "import math\n",
    "import copy\n",
    "os.environ['PYTHONASHSEED']= '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######## parameter #####\n",
    "batch_size = 8\n",
    "n_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "classes_name = []\n",
    "files_name = []\n",
    "for root, dirs, files in os.walk('lfw'):  \n",
    "    for name in dirs:\n",
    "        classes_name.append(name)\n",
    "    for name1 in files:\n",
    "        files_name.append(name1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5749\n",
      "13233\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(classes_name))\n",
    "print(len(files_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#  print(classes_name[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ Define  function to split  dataset #######################\n",
    "\n",
    "# import shutil, sys  \n",
    "# def split_dataset_into_test_and_train_sets(all_data_dir, training_data_dir, testing_data_dir, testing_data_pct):\n",
    "    \n",
    "#     if not os.path.exists(training_data_dir):\n",
    "#         os.makedirs(training_data_dir)\n",
    "#     if not os.path.exists(testing_data_dir):\n",
    "#         os.makedirs(testing_data_dir)\n",
    "#     # Recreate testing and training directories\n",
    "#     if testing_data_dir.count('/') > 1:\n",
    "#         shutil.rmtree(testing_data_dir, ignore_errors=False)\n",
    "#         os.makedirs(testing_data_dir)\n",
    "#         print(\"Successfully cleaned directory \" + testing_data_dir)\n",
    "#     else:\n",
    "#         print(\"Refusing to delete testing data directory \" + testing_data_dir + \" as we prevent you from doing stupid things!\")\n",
    "\n",
    "#     if training_data_dir.count('/') > 1:\n",
    "#         shutil.rmtree(training_data_dir, ignore_errors=False)\n",
    "#         os.makedirs(training_data_dir)\n",
    "#         print(\"Successfully cleaned directory \" + training_data_dir)\n",
    "#     else:\n",
    "#         print(\"Refusing to delete testing data directory \" + training_data_dir + \" as we prevent you from doing stupid things!\")\n",
    "\n",
    "#     num_training_files = 0\n",
    "#     num_testing_files = 0\n",
    "\n",
    "#     for subdir, dirs, files in os.walk(all_data_dir):\n",
    "#         category_name = os.path.basename(subdir)                        ### find  name  of classes\n",
    "\n",
    "#         # Don't create a subdirectory for the root directory\n",
    "#         print(category_name + \" vs \" + os.path.basename(all_data_dir))\n",
    "#         if category_name == os.path.basename(all_data_dir):\n",
    "#             continue\n",
    "\n",
    "#         training_data_category_dir = training_data_dir + '/' + category_name\n",
    "#         testing_data_category_dir = testing_data_dir + '/' + category_name\n",
    "\n",
    "#         if not os.path.exists(training_data_category_dir):\n",
    "#             os.mkdir(training_data_category_dir)\n",
    "\n",
    "#         if not os.path.exists(testing_data_category_dir):\n",
    "#             os.mkdir(testing_data_category_dir)\n",
    "\n",
    "#         for file in files:\n",
    "#             input_file = os.path.join(subdir, file)\n",
    "#             if np.random.rand(1) < testing_data_pct:\n",
    "#                 shutil.copy(input_file, testing_data_dir + '/' + category_name + '/' + file)\n",
    "#                 num_testing_files += 1\n",
    "#             else:\n",
    "#                 shutil.copy(input_file, training_data_dir + '/' + category_name + '/' + file)\n",
    "#                 num_training_files += 1\n",
    "\n",
    "#     print(\"Processed \" + str(num_training_files) + \" training files.\")\n",
    "#     print(\"Processed \" + str(num_testing_files) + \" testing files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########### Split data into train_data and test data\n",
    "#split_dataset_into_test_and_train_sets('lfw','train_data', 'test_data', 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_generator = ImageDataGenerator(\n",
    "#                         featurewise_center=False,\n",
    "#                         featurewise_std_normalization=False,\n",
    "#                         rotation_range=10,\n",
    "#                         width_shift_range=0.1,\n",
    "#                         height_shift_range=0.1,\n",
    "#                         zoom_range=.1,\n",
    "#                         horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10541 images belonging to 5749 classes.\n",
      "Found 2692 images belonging to 5749 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = 'train_data'\n",
    "test_path = 'test_data'\n",
    "train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size = (224,224), classes = classes_name, batch_size = batch_size)\n",
    "test_batches = ImageDataGenerator().flow_from_directory(test_path, target_size = (224,224), classes = classes_name, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5749\n",
      "10541\n",
      "5749\n",
      "2692\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "classes_name_train = []\n",
    "files_name_train = []\n",
    "classes_name_test = []\n",
    "files_name_test = []\n",
    "for root, dirs, files in os.walk('train_data'):  \n",
    "    for name in dirs:\n",
    "        classes_name_train.append(name)\n",
    "    for name1 in files:\n",
    "        files_name_train.append(name1)\n",
    "        \n",
    "for root, dirs, files in os.walk('test_data'):  \n",
    "    for name in dirs:\n",
    "        classes_name_test.append(name)\n",
    "    for name1 in files:\n",
    "        files_name_test.append(name1)\n",
    "\n",
    "no_training = len(files_name_train)\n",
    "no_testing = len(files_name_test)\n",
    "        \n",
    "print(len(classes_name_train))\n",
    "print(len(files_name_train))\n",
    "print(len(classes_name_test))\n",
    "print(len(files_name_test))\n",
    "number_classes = len(classes_name_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### fine_tune vgg_face \n",
    "def convblock(cdim, nb, bits=3):\n",
    "    L = []\n",
    "    \n",
    "    for k in range(1,bits+1):\n",
    "        convname = 'conv'+str(nb)+'_'+str(k)\n",
    "        #L.append( Convolution2D(cdim, 3, 3, border_mode='same', activation='relu', name=convname) ) # Keras 1\n",
    "        L.append( Convolution2D(cdim, kernel_size=(3, 3), padding='same', activation='relu', name=convname) ) # Keras 2\n",
    "    \n",
    "    L.append( MaxPooling2D((2, 2), strides=(2, 2)) )\n",
    "    \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg_face_blank():\n",
    "    \n",
    "    withDO = True # no effect during evaluation but usefull for fine-tuning\n",
    "    \n",
    "    if True:\n",
    "        mdl = Sequential()\n",
    "        \n",
    "        # First layer is a dummy-permutation = Identity to specify input shape\n",
    "        mdl.add( Permute((1,2,3), input_shape=(224,224,3)) ) # WARNING : 0 is the sample dim\n",
    "\n",
    "        for l in convblock(64, 1, bits=2):\n",
    "            mdl.add(l)\n",
    "\n",
    "        for l in convblock(128, 2, bits=2):\n",
    "            mdl.add(l)\n",
    "        \n",
    "        for l in convblock(256, 3, bits=3):\n",
    "            mdl.add(l)\n",
    "            \n",
    "        for l in convblock(512, 4, bits=3):\n",
    "            mdl.add(l)\n",
    "            \n",
    "        for l in convblock(512, 5, bits=3):\n",
    "            mdl.add(l)\n",
    "        \n",
    "        #mdl.add( Convolution2D(4096, 7, 7, activation='relu', name='fc6') ) # Keras 1\n",
    "        mdl.add( Convolution2D(4096, kernel_size=(7, 7), activation='relu', name='fc6') ) # Keras 2\n",
    "        if withDO:\n",
    "            mdl.add( Dropout(0.5) )\n",
    "        #mdl.add( Convolution2D(4096, 1, 1, activation='relu', name='fc7') ) # Keras 1\n",
    "        mdl.add( Convolution2D(4096, kernel_size=(1, 1), activation='relu', name='fc7') ) # Keras 2\n",
    "        if withDO:\n",
    "            mdl.add( Dropout(0.5) )\n",
    "        #mdl.add( Convolution2D(2622, 1, 1, name='fc8') ) # Keras 1\n",
    "        mdl.add( Convolution2D(number_classes, kernel_size=(1, 1), activation='relu', name='fc8') ) # Keras 2\n",
    "        mdl.add( Flatten() )\n",
    "        mdl.add( Activation('softmax') )\n",
    "        \n",
    "        return mdl\n",
    "    \n",
    "    else:\n",
    "        # See following link for a version based on Keras functional API :\n",
    "        # gist.github.com/EncodeTS/6bbe8cb8bebad7a672f0d872561782d9\n",
    "        raise ValueError('not implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = vgg_face_blank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "opt = Adam(lr=0.001, decay=10e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# model.compile(loss='hinge', optimizer='adadelta', metrics=['accuracy'])\n",
    "\n",
    "# sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# model.compile(loss='hinge', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " - 369s - loss: 16.1032 - acc: 5.6948e-04 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.00000, saving model to weights.VggFace.best.hdf5\n",
      "Epoch 2/500\n",
      " - 365s - loss: 16.1150 - acc: 1.8983e-04 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_acc did not improve\n",
      "Epoch 3/500\n",
      " - 362s - loss: 16.1150 - acc: 1.8983e-04 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_acc did not improve\n",
      "Epoch 4/500\n",
      " - 364s - loss: 16.1104 - acc: 4.7456e-04 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_acc did not improve\n",
      "Epoch 5/500\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "# Save check point\n",
    "filepath = \"weights.VggFace.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose =1, save_best_only = True, mode ='max')\n",
    "callbacks_list= [checkpoint]\n",
    "\n",
    "\n",
    "history = model.fit_generator(train_batches, steps_per_epoch = int(no_training / batch_size), validation_data = test_batches, validation_steps = int(no_testing / batch_size), epochs = n_epochs, shuffle=True, callbacks = callbacks_list, verbose =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('weights.VggFace.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred(kmodel, crpimg, transform=False):\n",
    "    \n",
    "    # transform=True seems more robust but I think the RGB channels are not in right order\n",
    "    \n",
    "    imarr = np.array(crpimg).astype(np.float32)\n",
    "\n",
    "    if transform:\n",
    "        imarr[:,:,0] -= 129.1863\n",
    "        imarr[:,:,1] -= 104.7624\n",
    "        imarr[:,:,2] -= 93.5940\n",
    "        #\n",
    "        # WARNING : in this script (https://github.com/rcmalli/keras-vggface) colours are switched\n",
    "        aux = copy.copy(imarr)\n",
    "        #imarr[:, :, 0] = aux[:, :, 2]\n",
    "        #imarr[:, :, 2] = aux[:, :, 0]\n",
    "\n",
    "        #imarr[:,:,0] -= 129.1863\n",
    "        #imarr[:,:,1] -= 104.7624\n",
    "        #imarr[:,:,2] -= 93.5940\n",
    "\n",
    "    #imarr = imarr.transpose((2,0,1)) # INFO : for 'th' setting of 'dim_ordering'\n",
    "    imarr = np.expand_dims(imarr, axis=0)\n",
    "\n",
    "    out = kmodel.predict(imarr)\n",
    "\n",
    "    best_index = np.argmax(out, axis=1)[0]\n",
    "    best_name = classes_name[best_index]    ###### \n",
    "    \n",
    "    print(best_index, best_name[0], out[0,best_index], [np.min(out), np.max(out)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs, labels = next(train_batches)\n",
    "\n",
    "crpim = imgs # WARNING : we deal with cropping in a latter section, this image is already fit\n",
    "pred(model, crpim, transform=False)\n",
    "pred(model, crpim, transform=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
